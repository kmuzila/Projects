{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVSS Score Prediction\n",
    "\n",
    "CVSS: Common Vulnerability Scoring System\n",
    "\n",
    "One of the thorniest problems in cybersecurity is how to prioritize work. There is often an overwhelming amount of work for frequently understaffed security teams. By predicting the severity score of a vulnerability, security teams can prioritize their which issue to address first to keep their organization safe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "word_punct_tokenizer = WordPunctTokenizer()\n",
    "word_net_lemmatizer = WordNetLemmatizer()\n",
    "snowball_stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cve = pd.read_csv(r'G:\\My Drive\\MIDS\\W207\\Final Project\\data\\cve.csv', header=0, index_col=0).drop_duplicates().dropna()\n",
    "products = pd.read_csv(r'G:\\My Drive\\MIDS\\W207\\Final Project\\data\\products.csv', header=0, index_col=0)\n",
    "vendors = pd.read_csv(r'G:\\My Drive\\MIDS\\W207\\Final Project\\data\\vendors.csv', header=0, index_col=0)\n",
    "vendor_product = pd.read_csv(r'G:\\My Drive\\MIDS\\W207\\Final Project\\data\\vendor_product.csv', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cve.mod_date = pd.to_datetime(cve.mod_date)\n",
    "cve.pub_date = pd.to_datetime(cve.pub_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Since we are trying to predict cvss scores using accompanying text data, we did some light preprocessing on the summary text then vectorized the words using Tfidf. Using weighted signals from the summary text helps the model gain further insight into the relationship between the severity score and the CVE. For the proof of concept, we also truncated the scores from float values to int, making it more straightforward for the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cve['access_authentication_ENCODED'] = pd.Categorical(cve['access_authentication'], categories=['NONE', 'SINGLE', 'MULTIPLE']).codes\n",
    "cve['access_complexity_ENCODED'] = pd.Categorical(cve['access_complexity'], categories=['LOW', 'MEDIUM', 'HIGH']).codes\n",
    "cve['access_vector_ENCODED'] = pd.Categorical(cve['access_vector'], categories=['LOCAL', 'NETWORK', 'ADJACENT_NETWORK']).codes\n",
    "cve['impact_availability_ENCODED'] = pd.Categorical(cve['impact_availability'], categories=['NONE', 'PARTIAL', 'COMPLETE']).codes\n",
    "cve['impact_integrity_ENCODED'] = pd.Categorical(cve['impact_integrity'], categories=['NONE', 'PARTIAL', 'COMPLETE']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cve = cve.merge(pd.get_dummies(cve['access_authentication'], prefix='access_authentication'), left_index=True, right_index=True)\n",
    "# cve = cve.merge(pd.get_dummies(cve['access_complexity'], prefix='access_complexity'), left_index=True, right_index=True)\n",
    "# cve = cve.merge(pd.get_dummies(cve['access_vector'], prefix='access_vector'), left_index=True, right_index=True)\n",
    "# cve = cve.merge(pd.get_dummies(cve['impact_availability'], prefix='impact_availability'), left_index=True, right_index=True)\n",
    "# cve = cve.merge(pd.get_dummies(cve['impact_confidentiality'], 'impact_confidentiality'), left_index=True, right_index=True)\n",
    "# cve = cve.merge(pd.get_dummies(cve['impact_integrity'], 'impact_integrity'), left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cve.drop('access_authentication', axis=1, inplace=True)\n",
    "cve.drop('access_complexity', axis=1, inplace=True)\n",
    "cve.drop('access_vector', axis=1, inplace=True)\n",
    "cve.drop('impact_availability', axis=1, inplace=True)\n",
    "cve.drop('impact_confidentiality', axis=1, inplace=True)\n",
    "cve.drop('impact_integrity', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cve['cvss'] = cve['cvss'].apply(np.floor)\n",
    "cve = cve[(cve[\"cvss\"] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cve[\"summary\"] = cve[\"summary\"].str.lower()\n",
    "cve[\"summary\"] = cve['summary'].apply(lambda x: re.sub(r\"\\W\", ' ', x))\n",
    "cve[\"summary\"] = cve['summary'].apply(lambda x: re.sub(r\"\\d+\", ' ', x))\n",
    "cve['summary'] = cve['summary'].apply(lambda x: ' '.join([item.translate(str.maketrans('', '', string.punctuation)) for item in word_punct_tokenizer.tokenize(x) if item.isalnum() if item not in stop_words]))\n",
    "cve['summary'] = cve['summary'].apply(lambda x: ' '.join([word_net_lemmatizer.lemmatize(item, pos=tag) for tag in  ('a', 'n', 'v') for item in word_punct_tokenizer.tokenize(x)]))\n",
    "cve['summary'] = cve['summary'].apply(lambda x: ' '.join([snowball_stemmer.stem(item) for item in word_punct_tokenizer.tokenize(x)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = cve['summary'].astype('str')\n",
    "labels = cve['cvss']\n",
    "tokenized_texts = [word_punct_tokenizer.tokenize(text) for text in texts]\n",
    "tfidf_vectorizer = TfidfVectorizer(tokenizer = lambda x: x, preprocessor = lambda x: x, min_df = 5, max_df = 0.8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(tokenized_texts, labels, test_size = 0.1, stratify = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tfidf = tfidf_vectorizer.fit_transform(x_train) \n",
    "x_test_tfidf = tfidf_vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "We are training multiple linear and classification models to see which performs the best on the data. The CVE severity scores are linear, but a model used for classification could perform well using the simplified scores and weighted text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(x_train_tfidf, y_train)\n",
    "knn_pred = knn_model.predict(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_model = DecisionTreeClassifier()\n",
    "decision_tree_model.fit(x_train_tfidf, y_train)\n",
    "decision_tree_pred = decision_tree_model.predict(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model = RandomForestClassifier()\n",
    "random_forest_model.fit(x_train_tfidf, y_train)\n",
    "random_forest_pred = random_forest_model.predict(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_boost_model = AdaBoostClassifier()\n",
    "ada_boost_model.fit(x_train_tfidf, y_train)\n",
    "ada_boost_pred = ada_boost_model.predict(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boost_model = GradientBoostingClassifier()\n",
    "gradient_boost_model.fit(x_train_tfidf, y_train)\n",
    "gradient_boost_pred = gradient_boost_model.predict(x_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_f1 = metrics.f1_score(y_test, knn_pred, average='micro')\n",
    "decision_tree_f1 = metrics.f1_score(y_test, decision_tree_pred, average='micro')\n",
    "random_forest_f1 = metrics.f1_score(y_test, random_forest_pred, average='micro')\n",
    "ada_boost_f1 = metrics.f1_score(y_test, ada_boost_pred, average='micro')\n",
    "gradient_boost_f1 = metrics.f1_score(y_test, gradient_boost_pred, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn f1 score: 0.5627710568363388\n",
      "decision_tree score: 0.615841132161607\n",
      "random_forest score: 0.6835197443506049\n",
      "ada_boost score: 0.46142433234421365\n",
      "gradient_boost score: 0.6141291942478886\n"
     ]
    }
   ],
   "source": [
    "print(f'knn f1 score: {knn_f1}')\n",
    "print(f'decision_tree score: {decision_tree_f1}')\n",
    "print(f'random_forest score: {random_forest_f1}')\n",
    "print(f'ada_boost score: {ada_boost_f1}')\n",
    "print(f'gradient_boost score: {gradient_boost_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Findings\n",
    "\n",
    "We see from the F1 scores that random forest is the highest performer. We can infer that the decisions tree performs well using the vectorized text, possibly due to the rigorous technical/security writing structure, which is usually uniform and has fairly standardized naming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "The following steps are to enrich the dataset with more data and improve our feature engineering. We can supplement the base dataset with data from several different sources:\n",
    "* MITRE CVE DB: The data we are using is a subset of this DB, and the remaining fields could enhance the models.\n",
    "* Project Zero DB: Project Zero DB contains tracking of vulnerabilities that have been exploited or patched with rich data that give us other severity indicators. (Ex: Time to patch can show the difficulty of exposure)\n",
    "* MITRE ATT&CK: This categorization has rich information above CVE data and its uses with concise categorical labels by attackers in the real world."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de42f773afd0019a808ee8a56a81a18886dc54bbb44685e6131ba4341cd86e88"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

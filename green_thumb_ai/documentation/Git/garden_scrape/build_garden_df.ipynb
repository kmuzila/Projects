{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/mrodr273/Veggies_GrowingGuide/blob/93998d60434a0166d5a1ff4276f9b34594b5fa95/BeautifulSoup.ipynb\n",
    "# https://github.com/mrodr273/Veggies_GrowingGuide/blob/93998d60434a0166d5a1ff4276f9b34594b5fa95/Veggies_GrowingGuide_WebScapping.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen('http://www.gardening.cornell.edu/homegardening/scene0391.html') as response:\n",
    "                            html = response.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html,'lxml')\n",
    "pages = []\n",
    "for link in soup.find_all('a')[8:-1]:\n",
    "    pages.append(str(link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_formated = []\n",
    "for page in pages:\n",
    "    start_scene = page.find(\"href\") + len(\"href\")+2\n",
    "    end_scene = page.find(\".html\")\n",
    "    substring_scene = page[start_scene:end_scene]\n",
    "\n",
    "    start_veggie = page.find(\".html\")+len(\".html\")+2\n",
    "    end_veggie = page.find('</a>')\n",
    "    substring_veggie = page[start_veggie:end_veggie]\n",
    "\n",
    "    page_formated = \"<a href=\\\"\"+substring_scene+\".html\\\">\"+substring_veggie+'</a>'\n",
    "    pages_formated.append(page_formated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = []\n",
    "veggies = []\n",
    "for page in pages_formated:\n",
    "    \n",
    "    pattern =  \"<a href=\\\"(.*?)\\\">(.*?)</a>\"\n",
    "\n",
    "    scene = re.search(pattern, page).group(1)\n",
    "    vegetable = re.search(pattern, page).group(2)\n",
    "    scenes.append(scene)\n",
    "    veggies.append(vegetable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base = \"http://www.gardening.cornell.edu/homegardening/\"\n",
    "url_scenes = []\n",
    "for scene in scenes:\n",
    "    url_scene = url_base+scene\n",
    "    url_scenes.append(url_scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "soups = []\n",
    "for url in url_scenes:\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "                            html = response.read()\n",
    "    soup = BeautifulSoup(html,'lxml')\n",
    "    soups.append(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_seasons = []\n",
    "veg_scientific_names = []\n",
    "veg_family = []\n",
    "veg_description = []\n",
    "for soup in soups:\n",
    "    basic_info = soup.find(\"div\", {\"class\": \"normal\"})\n",
    "    season = basic_info.find('p').get_text().strip()\n",
    "    scientific_name = basic_info.find('i').get_text().strip()\n",
    "    pattern =  \"(.*?) Family\"\n",
    "    family = re.search(pattern, basic_info.get_text()).group(1)\n",
    "    description = basic_info.find_all('p')[2].get_text().strip()\n",
    "    veg_seasons.append(season)\n",
    "    veg_scientific_names.append(scientific_name)\n",
    "    veg_family.append(family)\n",
    "    veg_description.append(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sunlight_all = []\n",
    "soil_condition_all = []\n",
    "hardiness_all = []\n",
    "lifecycle_all = []\n",
    "ease_care = []\n",
    "foliage_color_all = []\n",
    "foliage_texture_all = []\n",
    "tolerates_all = []\n",
    "special_charac_all = []\n",
    "for soup in soups:\n",
    "    if soup.find(text=\"Sunlight:\") != None:\n",
    "        sunlight = soup.find(text=\"Sunlight:\").next_element.next_element.get_text().strip()\n",
    "        sunlight_all.append(sunlight)\n",
    "    else:\n",
    "        sunlight_all.append(None)\n",
    "    \n",
    "    if soup.find(text=\"Soil conditions:\") != None:\n",
    "        soil_condition = soup.find(text=\"Soil conditions:\").next_element.next_element.next_element.get_text().strip()\n",
    "        soil_condition_all.append(soil_condition)\n",
    "    else:\n",
    "        soil_condition_all.append(None)\n",
    "    \n",
    "    if soup.find(text=\"Hardiness zones:\")!= None:\n",
    "        hardiness = soup.find(text=\"Hardiness zones:\").next_element.next_element.next_element.get_text().strip()\n",
    "        hardiness_all.append(hardiness)\n",
    "    else:\n",
    "        hardiness_all.append(None)\n",
    "    \n",
    "    if soup.find(text=\"Lifecycle:\") != None:\n",
    "        lifecycle = soup.find(text=\"Lifecycle:\").next_element.strip()\n",
    "        lifecycle_all.append(lifecycle)\n",
    "    else:\n",
    "        lifecycle_all.append(None)\n",
    "    \n",
    "    if soup.find(text=\"Ease-of-care:\") != None:\n",
    "        ease_of_care = soup.find(text=\"Ease-of-care:\").next_element.strip()\n",
    "        ease_care.append(ease_of_care)\n",
    "    else:\n",
    "        ease_care.append(None)\n",
    "\n",
    "    if soup.find(text=\"Foliage color:\") != None:\n",
    "        foliage_color = soup.find(text=\"Foliage color:\").next_element.strip()\n",
    "        foliage_color_all.append(foliage_color)\n",
    "    else:\n",
    "        foliage_color_all.append(None)\n",
    "\n",
    "    if soup.find(text=\"Foliage texture:\") != None:\n",
    "        foliage_texture = soup.find(text=\"Foliage texture:\").next_element.strip()\n",
    "        foliage_texture_all.append(foliage_texture)\n",
    "    else:\n",
    "        foliage_texture_all.append(None)\n",
    "\n",
    "    if soup.find(text=\"Tolerates:\") != None:\n",
    "        tolerates = soup.find(text=\"Tolerates:\").next_element.next_element.get_text().strip()\n",
    "        tolerates_all.append(tolerates)\n",
    "    else:\n",
    "        tolerates_all.append(None)\n",
    "        \n",
    "    if soup.find(text=\"Special characteristics:\") != None:\n",
    "        special_charac = soup.find(text=\"Special characteristics:\").next_element.next_element.get_text().strip()\n",
    "        special_charac_all.append(special_charac.replace('\\r','').replace('\\n','').replace('\\t',''))\n",
    "    else:\n",
    "        special_charac_all.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "how_to_grow = []\n",
    "germination_temp = []\n",
    "emergence_days = []\n",
    "seed_save = []\n",
    "\n",
    "for soup in soups:\n",
    "    item = soup.find(text=\"How to plant:\").next_element.next_element.get_text().strip().replace('\\t','').replace('\\r','').split('\\n')\n",
    "    while(\"\" in item) : \n",
    "        item.remove(\"\")\n",
    "    listToStr = ' '.join([str(element) for element in item]) \n",
    "    listToStr = listToStr.replace('Germination temperature', '').replace('Days to emergence','')\n",
    "    grow_info=re.split('[:]',listToStr)\n",
    "    how_to_grow.append(grow_info[0].replace('  ',''))\n",
    "    #fix comparison\n",
    "    if (len(grow_info) > 1):\n",
    "        germination_temp.append(grow_info[1])\n",
    "    else:\n",
    "        germination_temp.append('')\n",
    "    if (len(grow_info)>2):\n",
    "        piece = grow_info[2]\n",
    "        piece_start = piece.find('Seed can be saved')\n",
    "        if (piece_start)!= -1:\n",
    "            emergence_days.append(piece[:piece_start])\n",
    "            seed_save.append(piece[piece_start:])\n",
    "        else:\n",
    "            emergence_days.append(piece)\n",
    "            seed_save.append('')\n",
    "    else:\n",
    "        emergence_days.append('')\n",
    "        seed_save.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pests_info = []\n",
    "maintenance_info = []\n",
    "for soup in soups:\n",
    "    if soup.find(text=\"Maintenance and care:\") != None:\n",
    "        maintenance = soup.find(text=\"Maintenance and care:\").next_element.next_element.get_text().strip().replace('\\r','').replace('\\n','')\n",
    "        maintenance_info.append(maintenance)\n",
    "    else:\n",
    "        maintenance_info.append('')\n",
    "    if soup.find(text=\"Pests:\") != None:\n",
    "        pests = soup.find(text=\"Pests:\").next_element.next_element.get_text().replace('\\r','').replace('\\n','').replace('\\t','')\n",
    "        pests_info.append(pests)\n",
    "    else:\n",
    "        pests_info.append('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'veggie': veggies,'scene':scenes,'url_scene':url_scenes,'season':veg_seasons,'scientific_name':veg_scientific_names,'family':veg_family,'description': veg_description, 'sunlight':sunlight_all,'soil conditions':soil_condition_all,'hardiness':hardiness_all,'lifecycle':lifecycle_all,'ease of care':ease_care,'foliage colors':foliage_color_all,'foliage texture':foliage_texture_all,'tolerates':tolerates_all,'special characteristics':special_charac_all,'how to grow':how_to_grow,'germination temperature':germination_temp,'emergence days':emergence_days,'seed save time':seed_save,'Maintenance Info':maintenance_info,'Pests':pests_info}\n",
    "df = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('veggies_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.almanac.com/gardening/planting-calendar/zipcode/92861'\n",
    "req = urllib.request.Request(url,headers={'User-Agent' : 'Mozilla/5.0'})\n",
    "webpage = urllib.request.urlopen(req).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = BeautifulSoup(webpage,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pieces = page.find_all(\"tr\", {\"class\": \"plantrow\"})\n",
    "pieces_plants = []\n",
    "for piece in pieces:\n",
    "    pieces_plants.append(piece.find('a').get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "veggies_almanac = []\n",
    "for piece in pieces_plants:\n",
    "\n",
    "    index_end = piece.rfind('/')\n",
    "    veggies_almanac.append(piece[index_end+1:].capitalize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_veggies = veggies_almanac[:27]\n",
    "spring_veggies = veggies_almanac[27:]\n",
    "calendar_info = page.find_all(\"td\")\n",
    "dates = []\n",
    "\n",
    "for info in calendar_info:\n",
    "    dates.append(info.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "fall_dates = dates[:81]\n",
    "seed_indoors_fall = [fall_dates[x] for x in range(0, len(fall_dates), 3)]\n",
    "plant_outdoors_fall= [fall_dates[x+1] for x in range(0, len(fall_dates), 3)]\n",
    "start_outdoors_fall = [fall_dates[x+2] for x in range(0, len(fall_dates), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_fall = {'veggie': fall_veggies ,'seed indoors':seed_indoors_fall,'plant outdoors':plant_outdoors_fall,'start indoors': start_outdoors_fall}\n",
    "df_fall_calendar = pd.DataFrame(data=d_fall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "spring_dates = dates[81:]\n",
    "seed_indoors_spring = [spring_dates[x] for x in range(0, len(spring_dates), 3)]\n",
    "plant_seedlings_spring = [spring_dates[x+1] for x in range(0, len(spring_dates), 3)]\n",
    "start_outdoors_spring = [spring_dates[x+2] for x in range(0, len(spring_dates), 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_spring = {'veggie': spring_veggies ,'seed indoors':seed_indoors_spring,'plant seedlings':plant_seedlings_spring,'start indoors': start_outdoors_spring}\n",
    "df_spring_calendar = pd.DataFrame(data=d_spring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fall_calendar.to_csv('fall_calendar_df.csv')\n",
    "df_spring_calendar.to_csv('spring_calendar_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f5b7cf464915feb821f3811675706cbaac55ae9f8dc00e4c85073abfb24dd02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
